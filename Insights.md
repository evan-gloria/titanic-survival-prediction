## üîç Model Evaluation Summary

### üß™ Logistic Regression

**Validation Accuracy:** 81.0%  
**Cross-Validation Accuracy (mean):** 81.4%  
**Kaggle Public Score:** 0.75598

**Confusion Matrix:**

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 0 (Died)     | 0.83      | 0.87   | 0.85     | 110     |
| 1 (Survived) | 0.78      | 0.71   | 0.74     | 69      |

---

### üå≤ Random Forest

**Validation Accuracy:** 79.3%  
**Cross-Validation Accuracy (mean):** 81.9%  
**Kaggle Public Score:** **0.78229**

**Confusion Matrix:**

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 0 (Died)     | 0.78      | 0.92   | 0.85     | 110     |
| 1 (Survived) | 0.82      | 0.59   | 0.69     | 69      |

---

### ‚ö° XGBoost

**Validation Accuracy:** 79.9%  
**Cross-Validation Accuracy (mean):** **83.3%**  
**Kaggle Public Score:** 0.76555

**Confusion Matrix:**

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 0 (Died)     | 0.81      | 0.88   | 0.84     | 110     |
| 1 (Survived) | 0.78      | 0.67   | 0.72     | 69      |

---

### üìå Insights

- Random Forest had the **best Kaggle score** despite slightly lower validation accuracy.
- XGBoost had **strong cross-validation**, but slightly underperformed on Kaggle.
- Logistic Regression was stable and balanced, but had lower overall Kaggle performance.

---


## üîç Model Evaluation Summary After Adding `Title` Feature

### üß™ Logistic Regression

**Validation Accuracy:** 83.2%  
**Cross-Validation Accuracy (mean):** 82.6%  
**Kaggle Public Score:** 0.77511

**Confusion Matrix:**

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 0 (Died)     | 0.85      | 0.88   | 0.87     | 110     |
| 1 (Survived) | 0.80      | 0.75   | 0.78     | 69      |

---

### üå≤ Random Forest

**Validation Accuracy:** 82.7%  
**Cross-Validation Accuracy (mean):** 82.4%  
**Kaggle Public Score:** **0.77990**

**Confusion Matrix:**

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 0 (Died)     | 0.84      | 0.89   | 0.86     | 110     |
| 1 (Survived) | 0.81      | 0.72   | 0.76     | 69      |

---

### ‚ö° XGBoost

**Validation Accuracy:** 81.6%  
**Cross-Validation Accuracy (mean):** **83.95%**  
**Kaggle Public Score:** 0.77033

**Confusion Matrix:**

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 0 (Died)     | 0.83      | 0.88   | 0.85     | 110     |
| 1 (Survived) | 0.79      | 0.71   | 0.75     | 69      |

---

### üìå Insights

- `Title` is a **strong predictor** and improved all models.
- **Random Forest** currently performs best **overall** (highest Kaggle score).
- **XGBoost** shows the highest CV accuracy, but may need tuning to avoid overfitting.

---

## üîç Model Evaluation Summary After Adding `SoloTraveller` Feature

### üß™ Logistic Regression

- **Validation Accuracy:** 83.2%
- **Cross-Validation Accuracy (mean):** 82.6%
- **Kaggle Public Score:** 0.77511 *(no change)*

**Confusion Matrix:**

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 0 (Died)     | 0.85      | 0.88   | 0.87     | 110     |
| 1 (Survived) | 0.80      | 0.75   | 0.78     | 69      |

---

### üå≤ Random Forest

- **Validation Accuracy:** 82.7%
- **Cross-Validation Accuracy (mean):** 82.6%
- **Kaggle Public Score:** **0.78468** üîº *(Best so far)*

**Confusion Matrix:**

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 0 (Died)     | 0.84      | 0.88   | 0.86     | 110     |
| 1 (Survived) | 0.80      | 0.74   | 0.77     | 69      |

---

### ‚ö° XGBoost

- **Validation Accuracy:** 81.6%
- **Cross-Validation Accuracy (mean):** **83.95%**
- **Kaggle Public Score:** 0.77033 *(unchanged)*

**Confusion Matrix:**

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 0 (Died)     | 0.83      | 0.88   | 0.85     | 110     |
| 1 (Survived) | 0.79      | 0.71   | 0.75     | 69      |

---

### ‚úÖ Key Insights

- `SoloTraveller` offers **moderate improvement**, especially in Random Forest.
- **Random Forest** is now your **best-performing model on Kaggle**: `0.78468`
- **XGBoost** remains strong on cross-validation but still slightly underperforms on Kaggle test set.
- Logistic Regression remains stable, still outperforms many baselines.

---

## üìä Model Evaluation Summary ‚Äì After Adding Advanced Features

### ‚úÖ New Features Added:
- `Fare_per_person_log` ‚Äî Adjusted fare based on group size
- `Pclass_Fare` ‚Äî Captures class-fare interaction
- `Pclass_Title` ‚Äî Social class + role interaction

---

### üß™ Logistic Regression

- **Validation Accuracy:** 83.2%
- **Cross-Validation Accuracy (mean):** 82.6%
- **Confusion Matrix:**

- **F1 Score (Survived):** 0.77

‚úÖ **Best performing model** in terms of validation accuracy  
‚úÖ Well balanced between classes, especially for interpretable models

---

### üå≤ Random Forest

- **Validation Accuracy:** 81.0%
- **Cross-Validation Accuracy (mean):** 82.7%
- **Confusion Matrix:**

- **F1 Score (Survived):** 0.74

‚úÖ Strong performance  
üü° Slight drop in validation compared to previous best RF run  
‚úÖ CV score improved ‚Äî feature set generalizes better

---

### ‚ö° XGBoost

- **Validation Accuracy:** 79.3%
- **Cross-Validation Accuracy (mean):** **83.5%**
- **Confusion Matrix:**

- **F1 Score (Survived):** 0.72

‚úÖ **Highest CV score** ‚Äî model is learning rich non-linear patterns  
üü° Slightly lower performance on validation ‚Äî monitor overfitting

---

### üß† Key Insights

- Feature engineering significantly improved model interpretability and generalization
- `Pclass_Title`, `Fare_per_person_log`, and `Pclass_Fare` contributed noticeable gains
- Logistic Regression is now your **most consistent performer** (highest validation accuracy)
- XGBoost shows **the most potential** for tuning and boosting performance further