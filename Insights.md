# üîç Model Evaluation Summary

This project explores the Titanic dataset using iterative feature engineering, model evaluation, and Kaggle leaderboard comparison. We tested Logistic Regression, Random Forest, and XGBoost with increasing levels of complexity and selected the Random Forest model (Kaggle score: 0.78947) as the final winner based on generalization and performance. Logistic Regression came a close second (0.78708) and showed excellent simplicity and interpretability.

<details> 
<summary> <b> üîç Modelling with Base Features</b> </summary>

### üß™ Logistic Regression

**Validation Accuracy:** 81.0%  
**Cross-Validation Accuracy (mean):** 81.4%  
**Kaggle Public Score:** 0.75598

**Confusion Matrix:**

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 0 (Died)     | 0.83      | 0.87   | 0.85     | 110     |
| 1 (Survived) | 0.78      | 0.71   | 0.74     | 69      |

---

### üå≤ Random Forest

**Validation Accuracy:** 79.3%  
**Cross-Validation Accuracy (mean):** 81.9%  
**Kaggle Public Score:** **0.78229**

**Confusion Matrix:**

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 0 (Died)     | 0.78      | 0.92   | 0.85     | 110     |
| 1 (Survived) | 0.82      | 0.59   | 0.69     | 69      |

---

### ‚ö° XGBoost

**Validation Accuracy:** 79.9%  
**Cross-Validation Accuracy (mean):** **83.3%**  
**Kaggle Public Score:** 0.76555

**Confusion Matrix:**

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 0 (Died)     | 0.81      | 0.88   | 0.84     | 110     |
| 1 (Survived) | 0.78      | 0.67   | 0.72     | 69      |

---

### üìå Insights

- Random Forest had the **best Kaggle score** despite slightly lower validation accuracy.
- XGBoost had **strong cross-validation**, but slightly underperformed on Kaggle.
- Logistic Regression was stable and balanced, but had lower overall Kaggle performance.

</details>

---

<details>
<summary> <b> üîç Model Evaluation Summary After Adding `Title` Feature </b></summary>

### üß™ Logistic Regression

**Validation Accuracy:** 83.2%  
**Cross-Validation Accuracy (mean):** 82.6%  
**Kaggle Public Score:** 0.77511

**Confusion Matrix:**

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 0 (Died)     | 0.85      | 0.88   | 0.87     | 110     |
| 1 (Survived) | 0.80      | 0.75   | 0.78     | 69      |

---

### üå≤ Random Forest

**Validation Accuracy:** 82.7%  
**Cross-Validation Accuracy (mean):** 82.4%  
**Kaggle Public Score:** **0.77990**

**Confusion Matrix:**

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 0 (Died)     | 0.84      | 0.89   | 0.86     | 110     |
| 1 (Survived) | 0.81      | 0.72   | 0.76     | 69      |

---

### ‚ö° XGBoost

**Validation Accuracy:** 81.6%  
**Cross-Validation Accuracy (mean):** **83.95%**  
**Kaggle Public Score:** 0.77033

**Confusion Matrix:**

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 0 (Died)     | 0.83      | 0.88   | 0.85     | 110     |
| 1 (Survived) | 0.79      | 0.71   | 0.75     | 69      |

---

### üìå Insights

- `Title` is a **strong predictor** and improved all models.
- **Random Forest** currently performs best **overall** (highest Kaggle score).
- **XGBoost** shows the highest CV accuracy, but may need tuning to avoid overfitting.

</details>

---

<details>
<summary> <b> üîç Model Evaluation Summary After Adding `SoloTraveller` Feature </b></summary>

### üß™ Logistic Regression

- **Validation Accuracy:** 83.2%
- **Cross-Validation Accuracy (mean):** 82.6%
- **Kaggle Public Score:** 0.77511 *(no change)*

**Confusion Matrix:**

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 0 (Died)     | 0.85      | 0.88   | 0.87     | 110     |
| 1 (Survived) | 0.80      | 0.75   | 0.78     | 69      |

---

### üå≤ Random Forest

- **Validation Accuracy:** 82.7%
- **Cross-Validation Accuracy (mean):** 82.6%
- **Kaggle Public Score:** **0.78468** üîº *(Best so far)*

**Confusion Matrix:**

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 0 (Died)     | 0.84      | 0.88   | 0.86     | 110     |
| 1 (Survived) | 0.80      | 0.74   | 0.77     | 69      |

---

### ‚ö° XGBoost

- **Validation Accuracy:** 81.6%
- **Cross-Validation Accuracy (mean):** **83.95%**
- **Kaggle Public Score:** 0.77033 *(unchanged)*

**Confusion Matrix:**

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 0 (Died)     | 0.83      | 0.88   | 0.85     | 110     |
| 1 (Survived) | 0.79      | 0.71   | 0.75     | 69      |

---

### ‚úÖ Key Insights

- `SoloTraveller` offers **moderate improvement**, especially in Random Forest.
- **Random Forest** is now your **best-performing model on Kaggle**: `0.78468`
- **XGBoost** remains strong on cross-validation but still slightly underperforms on Kaggle test set.
- Logistic Regression remains stable, still outperforms many baselines.

</details>

---

<details>
<summary> <b> üîç Model Evaluation Summary ‚Äì After Adding Advanced Features </b></summary>

### ‚úÖ New Features Added:
- `Fare_per_person_log` ‚Äî Adjusted fare based on group size
- `Pclass_Fare` ‚Äî Captures class-fare interaction
- `Pclass_Title` ‚Äî Social class + role interaction

---

### üß™ Logistic Regression

- **Validation Accuracy:** 83.2%
- **Cross-Validation Accuracy (mean):** 82.6%
- **Confusion Matrix:**

- **F1 Score (Survived):** 0.77

‚úÖ **Best performing model** in terms of validation accuracy  
‚úÖ Well balanced between classes, especially for interpretable models

---

### üå≤ Random Forest

- **Validation Accuracy:** 81.0%
- **Cross-Validation Accuracy (mean):** 82.7%
- **Confusion Matrix:**

- **F1 Score (Survived):** 0.74

‚úÖ Strong performance  
üü° Slight drop in validation compared to previous best RF run  
‚úÖ CV score improved ‚Äî feature set generalizes better

---

### ‚ö° XGBoost

- **Validation Accuracy:** 79.3%
- **Cross-Validation Accuracy (mean):** **83.5%**
- **Confusion Matrix:**

- **F1 Score (Survived):** 0.72

‚úÖ **Highest CV score** ‚Äî model is learning rich non-linear patterns  
üü° Slightly lower performance on validation ‚Äî monitor overfitting

---

### üß† Key Insights

- Feature engineering significantly improved model interpretability and generalization
- `Pclass_Title`, `Fare_per_person_log`, and `Pclass_Fare` contributed noticeable gains
- Logistic Regression is now your **most consistent performer** (highest validation accuracy)
- XGBoost shows **the most potential** for tuning and boosting performance further

</details>

---

<details>
<summary> <b> üîç Model Evaluation Summary ‚Äì After Adding `Deck` </b></summary>

### üÜï Feature Added:
- `Deck` (one-hot encoded from Cabin letter)

---

### üß™ Logistic Regression

- **Validation Accuracy:** 83.2%
- **Cross-Validation Accuracy (mean):** ‚≠ê **83.17%**
- **Confusion Matrix:**

- **F1 Score (Survived):** 0.77

‚úÖ Highest validation performance across all models  
‚úÖ Improved recall for both classes  
‚úÖ Most balanced and consistent performer overall

---

### üå≤ Random Forest

- **Validation Accuracy:** 79.3%
- **Cross-Validation Accuracy (mean):** 82.49%
- **Confusion Matrix:**

- **F1 Score (Survived):** 0.72

üü° Slight dip in validation compared to previous run  
‚úÖ Still very solid generalization  
Deck feature might have added slight variance due to sparsity

---

### ‚ö° XGBoost

- **Validation Accuracy:** 78.2%
- **Cross-Validation Accuracy (mean):** **83.05%**
- **Confusion Matrix:**

- **F1 Score (Survived):** 0.71

‚úÖ Consistently improving CV accuracy ‚Äî now **second highest overall**  
üü° Slight underperformance on validation (may benefit from tuning)

---

### üß† Key Insights

- `Deck_Unknown` added moderate predictive power (MI: 0.050)
- Logistic Regression continues to shine due to **strong generalization**
- XGBoost shows potential with **non-linear signal extraction**, but may need hyperparameter tuning
- Random Forest remains competitive but plateauing

</details>

---

<details>
<summary> <b> üå≤ Random Forest ‚Äì Hyperparameter Tuning Results (RandomizedSearchCV) </b></summary>

After engineering key features (e.g., Title, Fare_per_person, Pclass_Title, Deck), we performed hyperparameter tuning on the Random Forest model using `RandomizedSearchCV` to further optimize performance.

---

### üîß Best Parameters Identified

```python
{
  'bootstrap': True,
  'max_depth': 20,
  'max_features': 'sqrt',
  'min_samples_leaf': 3,
  'min_samples_split': 8,
  'n_estimators': 497
}
```

Best Parameters: {'bootstrap': True, 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 497}

**Accuracy:** 0.8100558659217877

**Confusion Matrix:**

|               | Predicted: 0 | Predicted: 1 |
|---------------|--------------|--------------|
| **Actual: 0** |     96      |     14       |
| **Actual: 1** |      20      |     49       |

**Classification Report:**

|            |   precision  |  recall | f1-score  | support |
|----|----|----|----|----|
|           0   |    0.83  |    0.87   |   0.85    |   110 |
|           1   |    0.78  |    0.71   |   0.74    |    69 |
|   |   |   |   |   |
|    accuracy   |          |           |   0.81    |   179 |
|   macro avg   |   0.80   |  0.79   |  0.80   |   179   |
|weighted avg   |   0.81   |  0.81   |  0.81   |   179    |

### üß™ Validation Set Performance

- Precision (Survived = 1): 0.78
- Recall (Survived = 1): 0.71
- F1 Score (Survived = 1): 0.74

### üß† Interpretation
- The tuned model performed similarly to the default model on the validation set.
- However, the Kaggle test score decreased, suggesting possible overfitting or reduced generalization.
- The Deck feature and other one-hot encoded variables may have introduced variance or sparsity that the tuned model became sensitive to.
- In contrast, the default model appears to have better robustness under real test distribution conditions.

### ‚úÖ Key Takeaways
- RandomizedSearchCV helped explore a broader range of hyperparameters.
- Tuning did not improve generalization on the unseen Kaggle test set.
- The default Random Forest model remains the best performer based on public leaderboard score.
- Tuning is still valuable in more complex datasets or when default models underperform.
- Logistic Regression, with higher CV accuracy, should be tested next for potential improvement.

</details>

---

<details>
<summary> <b> ü§ù Voting Ensemble (Logistic Regression + Random Forest + XGBoost) </b></summary>

To combine the strengths of different model types, we created a soft-voting ensemble using:

- `LogisticRegression` (linear model with high CV accuracy)
- `RandomForestClassifier` (robust to noise, strong baseline)
- `XGBClassifier` (captures non-linear interactions)

The ensemble used **soft voting**, which averages predicted probabilities to make the final decision.

---

### üß™ Validation Performance

**Accuracy:** 81.56%

**Confusion Matrix:**

|               | Predicted: 0 | Predicted: 1 |
|---------------|--------------|--------------|
| **Actual: 0** |     97      |     13       |
| **Actual: 1** |      20      |     49       |

- **Precision (Survived = 1):** 0.79  
- **Recall (Survived = 1):** 0.71  
- **F1 Score (Survived = 1):** 0.75  
- **Weighted F1 Score:** 0.81  

üìå Interpretation:
- The ensemble showed **balanced performance**, particularly strong on class 0 (non-survivors), with reasonable recall for class 1.
- It **matched the performance** of the tuned Random Forest on the validation set.
- Shows promise in combining generalization (LogReg) and non-linear detection (RF/XGB).

---

### üì§ Kaggle Submission Result

- **Public Score:** üîª **0.77272**
- Same as the tuned Random Forest, indicating ensemble did not improve generalization over single best model.
- May have suffered from overlapping patterns or added complexity without enough additional signal.

---

### ‚úÖ Takeaways

- Ensemble models can help stabilize predictions but don‚Äôt always outperform the strongest single model.
- In this case, **default Random Forest (score: 0.78947)** still generalizes best.
- Logistic Regression remains promising for its generalization potential and simplicity.

</details>

---

<details>
<summary> <b> ‚úÇÔ∏è Logistic Regression ‚Äì Feature Pruning </b></summary>

After analyzing Mutual Information and category sparsity, we removed the following low-impact or noisy features:

Dropped columns:
- Title_Rare
- Embarked_Q
- Deck_G, Deck_F, Deck_C
- Pclass_Title_3_Master
- Pclass_Title_3_Mrs
- Pclass_Title_1_Rare
- Pclass_Title_2_Rare


### üìä Validation Performance

**Accuracy: 83.24%**

**Confusion Matrix:**

|               | Predicted: 0 | Predicted: 1 |
|---------------|--------------|--------------|
| **Actual: 0** |     100      |     10       |
| **Actual: 1** |      20      |     49       |

- F1 Score (Survived = 1): 0.77
- Weighted F1 Score: 0.83
- Cross-Validation Accuracy (mean): 82.49%

### üì§ Kaggle Submission Result ‚Äì Logistic Regression

- **Public Score:** ‚úÖ **0.78708**
- **Second best score overall**, just behind Random Forest (0.78947)
- Stronger than XGBoost and Voting Ensemble

---

### ‚úÖ Interpretation


- Model retains strong performance after feature pruning
- Slight increase in precision for class 1 (survivors)
- Cleaned feature space may help generalize better to test data
- Logistic Regression with mutual info‚Äìbased feature pruning **generalizes very well**
- Removing rare or low-impact one-hot columns reduced potential overfitting
- Confirms that **simpler models** with good feature engineering can match or exceed tuned tree-based models

</details>

---
> 

# üß† Key Model Comparisons

| Model                    | Kaggle Score | Notes                                        |
|--------------------------|--------------|----------------------------------------------|
| **Random Forest (Base features + Title + SoloTraveller + Fare_per_person_log + Pclass_Fare + Pclass_Title)** | **0.78947**     | Best score, strong generalizer               |
| **Logistic Regression (pruned)** | **0.78708**     | Simplest, most interpretable, clean features |
| Random Forest (tuned)    | 0.77272      | Overfit slightly                             |
| Voting Ensemble          | 0.77272      | No gain from combining models                |
| XGBoost (default)        | ~0.765‚Äì0.77  | Lower performance, needs tuning              |

---

## üöÄ Takeaways

- Logistic Regression is now a **reliable fallback model**
- Random Forest is your **best-scoring model**, but LogReg is **lighter, faster, and robust**
- No further feature engineering is strictly required ‚Äî you‚Äôve covered the high-value space